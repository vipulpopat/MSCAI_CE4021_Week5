{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Student Name:Ganapathy S\n",
    "## Student ID:18202799\n",
    "\n",
    "Making use of Numpy, write a Python class to apply the PCA transform to the provided (see Notebook) data set. Compare the output of your implementation to the PCA functionality provided by the Scikitlearn module.\n",
    "\n",
    " - Create a 'fit' method that calculates the eigen vectors and eigen values of your dataset. Compare your results to the output of Scikitlearn's fit method and document your findings as a comment (use markdown) directly under the cell with your PCA class.\n",
    " - Use the Scikitlean's PCA class with n_components=2 and n_components=1 and observe the differences. In the cell directly below, comment on what you have observed.\n",
    " - Add a property to your class and initialise this property in a suitable fashion to allow you to choose the number of principal components similar to the Scikitlearn PCA class.\n",
    " - Store those results from your fit method that are required to transform the data set, in suitable class properties.\n",
    " - Create a 'transform' method to perform the PCA data transformation on your data set using the parameters obtained using your 'fit' method.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'as' keyword allows you to invoke functionality from the module using an alias for the module name. For example: np.mean() instead of numpy.mean()\n",
    "- The from keyword allows you to only import the functionality of interest, for example above we import only the PCA class from the sklearn.decomposition module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T11:04:46.564792Z",
     "start_time": "2018-10-14T11:04:45.460018Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import eig\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per E-tivity instructions: Use of the matrix class is discouraged, but to allow us to simplify the code slightly, we will use it this week. Its first use will be to store the data that you will perform the PCA transform on. Note that you will likely obtain a higher score if your final version does not use the matrix class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T11:04:47.063136Z",
     "start_time": "2018-10-14T11:04:47.059134Z"
    }
   },
   "outputs": [],
   "source": [
    "a_x = 0.05\n",
    "a_y = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T11:04:47.832655Z",
     "start_time": "2018-10-14T11:04:47.827651Z"
    }
   },
   "outputs": [],
   "source": [
    "data = np.array([[n*(1+a_x*(rand.random()-0.5)), 4*n + a_y * (rand.random()-0.5)] for n in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy shape property is very useful to get an insight in the dimensions of your data, for example to check whether the features (in this case 2) or the samples (in this case 20) are in the rows or the columns. The notation used here (with columns containing the features and rows containing separate examples) is the standard for Scikitlearn and many other machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T11:04:51.584639Z",
     "start_time": "2018-10-14T11:04:51.397504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Development of my own PCA class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-14T11:04:54.908214Z",
     "start_time": "2018-10-14T11:04:54.895207Z"
    }
   },
   "outputs": [],
   "source": [
    "class PCA_class:\n",
    "    \"\"\"Principal component analysis (PCA)\n",
    "     \n",
    "    Linear dimensionality reduction using Singular Value Decomposition of the\n",
    "    data to project it to a lower dimensional space.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,n_components=None):\n",
    "        self.n_components = n_components\n",
    "        self.components_ = []\n",
    "        \n",
    "    def fit(self, data):\n",
    "        \"\"\"Fit the model with provided data\"\"\"\n",
    "        \n",
    "        # Step 1: Get the data\n",
    "        self.data = data   \n",
    "        \n",
    "        # Step 2: Get mean of data and center around zero mean\n",
    "        self.mean_data = self.data.mean(axis=0)\n",
    "        \n",
    "        # Center data\n",
    "        self.data_with_zero_mean = self.data - self.mean_data\n",
    "\n",
    "        # Step 3: Calculate the covariance matrix of the Centered Data\n",
    "        self.covariance_matrix = np.cov(self.data_with_zero_mean, rowvar=False)\n",
    "        \n",
    "        # Step 4: Calculate the eigenvectors and eigenvalues of the covariance matrix\n",
    "        eigen_values, eigen_vectors = eig(self.covariance_matrix)    \n",
    "        \n",
    "        # Sort the eigen values and eigen vectors\n",
    "        sorted_eig_val = eigen_values[np.square(eigen_values).argsort()[::-1]]\n",
    "        sorted_eig_vec = eigen_vectors[:, np.square(eigen_values).argsort()[::-1]]\n",
    "        \n",
    "        # n_components will filter the eigen vectors\n",
    "        self.eigen_val= sorted_eig_val[:self.n_components]\n",
    "        self.eigen_vec = sorted_eig_vec[:, :self.n_components]         \n",
    "        self.components_ = self.eigen_vec\n",
    "        \n",
    "        return self.eigen_val, self.eigen_vec\n",
    "    \n",
    "    def trans(self, data):\n",
    "        \"\"\"Transform the data by calculating the projection. \"\"\" \n",
    "        \n",
    "        # Step 5: Choosing components and forming a feature vector and applying Projection\n",
    "        # Thanks to Brian Parle to highlighting I was not using the data passed as function argument\n",
    "        data = data - self.mean_data\n",
    "        self.projected_data = data.dot(self.eigen_vec)\n",
    "        return self.projected_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.38910935e+02, 4.80286341e-01]), array([[-0.23314932, -0.97244095],\n",
       "        [-0.97244095,  0.23314932]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(array([6.38910935e+02, 4.80286341e-01]), array([[-0.23314932, -0.97244095],\n",
       "        [-0.97244095,  0.23314932]]))"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 42.38641972,  -0.37919926],\n",
       "       [ 36.96841577,  -0.11807054],\n",
       "       [ 34.44163557,  -0.5646788 ],\n",
       "       [ 23.95721776,   1.00621226],\n",
       "       [ 26.06303544,  -0.54754172],\n",
       "       [ 17.02321821,   0.5515776 ],\n",
       "       [ 18.03782861,  -0.75456142],\n",
       "       [  8.15466486,   0.69459014],\n",
       "       [  9.16722421,  -0.73588531],\n",
       "       [ -1.0465415 ,   0.98833693],\n",
       "       [ -5.86475472,   0.84485881],\n",
       "       [ -5.8422224 ,  -0.18949802],\n",
       "       [-12.92167353,   0.67397325],\n",
       "       [-16.83580549,   0.2167668 ],\n",
       "       [-21.58445141,   0.29779655],\n",
       "       [-25.5177576 ,   0.71517567],\n",
       "       [-25.4098544 ,  -0.75678256],\n",
       "       [-27.901691  ,  -1.31721982],\n",
       "       [-33.09927012,  -0.54473572],\n",
       "       [-40.17563799,  -0.08111484]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "AttributeError",
     "evalue": "'PCA_class' object has no attribute 'explained_variance_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-a355267a32ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Scikit PCA values:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mscikit_pca_eigen_vectors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscikit_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomponents_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mscikit_pca_eigen_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscikit_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplained_variance_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'PCA_class' object has no attribute 'explained_variance_'"
     ]
    }
   ],
   "source": [
    "# Run the Implemented PCA\n",
    "Execute_pca = PCA_class(n_components=2)\n",
    "Execute_pca.fit(data)\n",
    "Execute_projected_data_2 = Execute_pca.trans(data)\n",
    "\n",
    "# Store the PCA values:\n",
    "Execute_pca_eigen_vectors = Execute_pca.components_\n",
    "Execute_pca_eigen_values = Execute_pca.eigen_val\n",
    "\n",
    "#Scikit PCA\n",
    "scikit_pca = PCA_class(n_components=2)\n",
    "scikit_pca.fit(data)\n",
    "scikit_pca.trans(data)\n",
    "\n",
    "# Scikit PCA values:\n",
    "scikit_pca_eigen_vectors = scikit_pca.components_\n",
    "scikit_pca_eigen_values = scikit_pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
