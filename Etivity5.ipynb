{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Michel Danjou\n",
    "Student ID: 18263461"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'as' keyword allows you to invoke functionality from the module using an alias for the module name. For example: np.mean() instead of numpy.mean()\n",
    "- The from keyword allows you to only import the functionality of interest, for example above we import only the PCA class from the sklearn.decomposition module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import eig\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per E-tivity instructions: Use of the matrix class is discouraged, but to allow us to simplify the code slightly, we will use it this week. Its first use will be to store the data that you will perform the PCA transform on. Note that you will likely obtain a higher score if your final version does not use the matrix class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_x = 0.05\n",
    "a_y= 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data =  np.matrix([[n*(1+a_x*(rand.random()-0.5)),4*n+ a_y*(rand.random()-0.5)] for n in range(20)])\n",
    "data =  np.matrix([[n*(1+a_x*(rand.random()-0.5)),4*n+ a_y*(rand.random()-0.5)] for n in range(20)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy shape property is very useful to get an insight in the dimensions of your data, for example to check whether the features (in this case 2) or the samples (in this case 20) are in the rows or the columns. The notation used here (with columns containing the features and rows containing separate examples) is the standard for Scikitlearn and many other machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n",
      "[[ 0.          4.14656817]\n",
      " [ 1.02310036  8.51322675]\n",
      " [ 2.01239035  9.15115242]\n",
      " [ 3.00225114  9.6606455 ]\n",
      " [ 4.09852886 19.29371226]\n",
      " [ 5.00357848 22.12927107]\n",
      " [ 6.09978631 27.61125185]\n",
      " [ 6.8843758  24.60789524]\n",
      " [ 7.98449106 34.80309688]\n",
      " [ 8.77962992 31.78479252]\n",
      " [10.02214812 38.6168585 ]\n",
      " [11.1472456  45.89093366]\n",
      " [12.01691203 52.79079839]\n",
      " [12.73588537 48.02836754]\n",
      " [14.27944104 51.83876991]\n",
      " [15.05898697 55.45093017]\n",
      " [16.12890754 63.98479441]\n",
      " [17.22592229 69.06149794]\n",
      " [18.44831318 70.79169443]\n",
      " [19.36691738 71.14046299]]\n",
      "(20, 2)\n",
      "\n",
      "scikit.pca with nb_components=2\n",
      "eigen_values: [5.24002641e+02 5.21638274e-01]\n",
      "eigen_vectors: [[-0.26062686 -0.96543961]\n",
      " [-0.96543961  0.26062686]]\n",
      "transformed_data: [[ 3.51426364e+01  4.21388990e-01]\n",
      " [ 3.06602438e+01  5.71715893e-01]\n",
      " [ 2.97865295e+01 -2.17123282e-01]\n",
      " [ 2.90366604e+01 -1.03998652e+00]\n",
      " [ 1.94507968e+01  4.12259484e-01]\n",
      " [ 1.64773558e+01  2.77511527e-01]\n",
      " [ 1.08991332e+01  6.47940499e-01]\n",
      " [ 1.35942075e+01 -8.92288676e-01]\n",
      " [ 3.46463643e+00  7.02759869e-01]\n",
      " [ 6.17139247e+00 -8.51549865e-01]\n",
      " [-7.48388253e-01 -2.70506248e-01]\n",
      " [-8.06429916e+00  5.39099447e-01]\n",
      " [-1.49523603e+01  1.49777910e+00]\n",
      " [-1.05419047e+01 -4.37563635e-01]\n",
      " [-1.46229101e+01 -9.34680214e-01]\n",
      " [-1.83134033e+01 -7.45858750e-01]\n",
      " [-2.68311839e+01  4.45351800e-01]\n",
      " [-3.20183461e+01  7.09375607e-01]\n",
      " [-3.40073342e+01 -1.98333000e-02]\n",
      " [-3.45834621e+01 -8.15791725e-01]]\n",
      "\n",
      "scikit.pca with nb_components=1\n",
      "eigen_values: [524.0026415]\n",
      "eigen_vectors: [[-0.26062686 -0.96543961]]\n",
      "transformed_data: [[ 35.14263638]\n",
      " [ 30.66024379]\n",
      " [ 29.78652954]\n",
      " [ 29.03666042]\n",
      " [ 19.45079679]\n",
      " [ 16.47735577]\n",
      " [ 10.89913317]\n",
      " [ 13.59420751]\n",
      " [  3.46463643]\n",
      " [  6.17139247]\n",
      " [ -0.74838825]\n",
      " [ -8.06429916]\n",
      " [-14.9523603 ]\n",
      " [-10.54190468]\n",
      " [-14.62291014]\n",
      " [-18.31340333]\n",
      " [-26.83118393]\n",
      " [-32.01834611]\n",
      " [-34.00733423]\n",
      " [-34.58346215]]\n",
      "\n",
      "pca homebrew nb_components= 2\n",
      "eigen_values: [5.24002641e+02 5.21638274e-01]\n",
      "eigen_vectors: [[ 0.26062686 -0.96543961]\n",
      " [-0.96543961 -0.26062686]]\n",
      "\n",
      "pca homebrew nb_components= 1\n",
      "eigen_values: [524.0026415]\n",
      "eigen_vectors: [[ 0.26062686 -0.96543961]]\n",
      "\n",
      "Transform using homebrew code, nb_components= 2\n",
      "Transform: [[ -4.00326116  -7.95235888  -8.31040205  -8.54430253 -17.55872733\n",
      "  -20.06040787 -25.06722806 -21.96318353 -31.51931544 -28.39809031\n",
      "  -34.6702038  -41.39965346 -47.83439774 -43.04917459 -46.32559591\n",
      "  -49.60974789 -57.56982842 -62.18516757 -63.5369799  -63.63428196]\n",
      " [ -1.08070704  -3.20651717  -4.32787747  -5.41631587  -8.98534175\n",
      "  -10.59813528 -13.08520919 -13.05992755 -16.77916579 -16.76017315\n",
      "  -19.74036934 -22.72240238 -25.36030288 -24.81321082 -27.29651381\n",
      "  -28.99054431 -32.24764225 -34.62986904 -36.2609493  -37.23870464]]\n",
      "\n",
      "Transform using homebrew code, nb_components= 1\n",
      "Transform: [[ -4.00326116  -7.95235888  -8.31040205  -8.54430253 -17.55872733\n",
      "  -20.06040787 -25.06722806 -21.96318353 -31.51931544 -28.39809031\n",
      "  -34.6702038  -41.39965346 -47.83439774 -43.04917459 -46.32559591\n",
      "  -49.60974789 -57.56982842 -62.18516757 -63.5369799  -63.63428196]\n",
      " [ -1.08070704  -3.20651717  -4.32787747  -5.41631587  -8.98534175\n",
      "  -10.59813528 -13.08520919 -13.05992755 -16.77916579 -16.76017315\n",
      "  -19.74036934 -22.72240238 -25.36030288 -24.81321082 -27.29651381\n",
      "  -28.99054431 -32.24764225 -34.62986904 -36.2609493  -37.23870464]]\n"
     ]
    }
   ],
   "source": [
    "%reset\n",
    "\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import eig\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "        \n",
    "class Log:\n",
    "    DEBUG = 1\n",
    "    INFO = 2\n",
    "    ERROR = 3\n",
    "\n",
    "\n",
    "class My_pca:\n",
    "    \"\"\"\n",
    "    Perform the PCA on a dataset\n",
    "    \n",
    "    There is a lot of log statements in this class. I intend to remove\n",
    "    them in the final code. Leaving them in place for the time being as they\n",
    "    are useful for debugging. \n",
    "    \n",
    "    BUG ALERT\n",
    "    =========\n",
    "    The eigen values calculated by this class match the ones calculated by \n",
    "    scikit. \n",
    "    \n",
    "    However, it appears that one of the eigen vectors is the negative version \n",
    "    of the one calculted by scikit. Currently investigating the reason behind \n",
    "    this.\n",
    "        \n",
    "    \"\"\"\n",
    "\n",
    "    log_level = Log.ERROR\n",
    "    nb_components = 2\n",
    "    eigen_values = []\n",
    "    eigen_vectors = []\n",
    "\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\" init \"\"\"\n",
    "\n",
    "\n",
    "    def __log__(self, message, level=Log.INFO):\n",
    "        \"\"\"\n",
    "        Log a message only if its log level is equal or superior to self.log_level\n",
    "        \"\"\"\n",
    "        if level >= self.log_level:\n",
    "            print(message)\n",
    "\n",
    "        \n",
    "    def fit(self, matrix):\n",
    "        \"\"\" \n",
    "        Explicitly using array manipulation instead of \n",
    "        easier matrix operations \n",
    "        \"\"\"\n",
    "        self.matrix = matrix\n",
    "        \n",
    "        # Calculate mean values of each column from dataset\n",
    "        m0 = np.mean(self.matrix[:,0])\n",
    "        m1 = np.mean(self.matrix[:,1])\n",
    "        self.__log__((\"=\"*80))\n",
    "        self.__log__(\"mean.col0:{} \".format(m0))\n",
    "        self.__log__(\"mean.col1:{} \".format(m1))       \n",
    "        \n",
    "        # Center the columns by subtracting the corresponding mean\n",
    "        c0 = matrix[:,0] - m0\n",
    "        c1 = matrix[:,1] - m1\n",
    "        self.__log__(\"c0       :{} \".format(c0), Log.DEBUG)\n",
    "        self.__log__(\"c1       :{} \".format(c1), Log.DEBUG)       \n",
    "        \n",
    "        # Create a centered matrix \n",
    "        c_matrix = np.append(c0, c1, axis=1)\n",
    "        self.__log__(\"centered_matrix:\\n{}\".format(c_matrix), Log.DEBUG)\n",
    "        \n",
    "        # Calculate covariance of centered matrix\n",
    "        my_cov = np.cov(c_matrix, rowvar=False)        \n",
    "        self.__log__(\"covariance:\\n{}\".format(my_cov), Log.DEBUG)\n",
    "    \n",
    "        # eigen values, eigen vectors\n",
    "        eigen_values, eigen_vectors = eig(my_cov)\n",
    "        self.__log__(\"eigen_values:\\n{}\".format(eigen_values))\n",
    "        self.__log__(\"eigen_vectors:\\n{}\".format(eigen_vectors))     \n",
    "        \n",
    "        # order eigen values and eigen vectors       \n",
    "        sorted_eigen_values_indexes = eigen_values.argsort()[::-1]\n",
    "        sorted_eigen_values = eigen_values[sorted_eigen_values_indexes]\n",
    "        sorted_eigen_vectors = eigen_vectors[sorted_eigen_values_indexes] \n",
    "        self.__log__(\"sorted_eigen_values_indexes:\\n{}\".format(sorted_eigen_values_indexes))\n",
    "        self.__log__(\"sorted_eigen_values:\\n{}\".format(sorted_eigen_values))\n",
    "        self.__log__(\"sorted_eigen_vectors:\\n{}\".format(sorted_eigen_vectors))\n",
    "\n",
    "        # use nb_components to decide how many eigen vectors to keep\n",
    "        filtered_sorted_eigen_values = sorted_eigen_values[:self.nb_components]\n",
    "        filtered_sorted_eigen_vectors = sorted_eigen_vectors[:self.nb_components] \n",
    "        self.__log__(\"filtered_sorted_eigen_values:\\n{}\".format(sorted_eigen_values))\n",
    "        self.__log__(\"filtered_sorted_eigen_vectors:\\n{}\".format(sorted_eigen_vectors))\n",
    "        \n",
    "        # calculate projection of dataset onto the eigen vector basis\n",
    "        #P = eigen_vectors.T.dot(c_matrix.T)        \n",
    "        #self.__log__(\"projected  :\\n{}\".format(P.T), Log.DEBUG)\n",
    "        \n",
    "        # save results as class variables\n",
    "        self.eigen_values = filtered_sorted_eigen_values\n",
    "        self.eigen_vectors = filtered_sorted_eigen_vectors\n",
    "            \n",
    "    \n",
    "    def transform(self, data):\n",
    "        \"\"\"\n",
    "        Calculate projection of dataset onto the eigen vector basis\n",
    "        \n",
    "        BUG:\n",
    "        This method does work yet...\n",
    "        \"\"\"\n",
    "        self.fit(data)\n",
    "        self.projection = self.eigen_vectors.T.dot(data.T)\n",
    "        \n",
    "        self.__log__(\"eigen_values:\\n{}\".format(self.eigen_values), Log.DEBUG)\n",
    "        self.__log__(\"eigen_vectors:\\n{}\".format(self.eigen_vectors), Log.DEBUG)\n",
    "        self.__log__(\"projected  :\\n{}\".format(self.projection), Log.DEBUG)\n",
    "        \n",
    "        \n",
    "        \n",
    "def build_dataset():\n",
    "    \"\"\"\n",
    "    Create a dataset\n",
    "    \"\"\"\n",
    "    a_x = 0.05\n",
    "    a_y= 10\n",
    "\n",
    "    data =  np.matrix([[n*(1+a_x*(rand.random()-0.5)),4*n+ a_y*(rand.random()-0.5)] for n in range(20)])\n",
    "\n",
    "    print(data)\n",
    "    print(data.shape)\n",
    "    return data\n",
    "\n",
    "\n",
    "def scikit_pca( matrix, nb_components):\n",
    "    \"\"\"\n",
    "    Calculate the PCA using Scikit APIs\n",
    "    \"\"\"\n",
    "    pca = PCA(nb_components)\n",
    "    pca.fit(matrix)\n",
    "\n",
    "    return pca\n",
    "\n",
    "      \n",
    "def test():\n",
    "\n",
    "    my_pca = My_pca()\n",
    "\n",
    "    # Calculate PCA using scikit, nb_components=2\n",
    "    pca = scikit_pca(data, 2)\n",
    "    print()\n",
    "    print(\"scikit.pca with nb_components=2\")\n",
    "    print(\"eigen_values:\", pca.explained_variance_)\n",
    "    print(\"eigen_vectors:\", pca.components_)\n",
    "    print(\"transformed_data:\", pca.transform(data))\n",
    "\n",
    "    # Calculate PCA using scikit, nb_components=1\n",
    "    pca = scikit_pca(data, 1)\n",
    "    print()\n",
    "    print(\"scikit.pca with nb_components=1\")\n",
    "    print(\"eigen_values:\", pca.explained_variance_)\n",
    "    print(\"eigen_vectors:\", pca.components_)\n",
    "    print(\"transformed_data:\", pca.transform(data))\n",
    "\n",
    "    # Calculate PCA using homebrew code, nb_components=2\n",
    "    my_pca.nb_components=2\n",
    "    my_pca.fit(data)\n",
    "    print()\n",
    "    print(\"pca homebrew nb_components=\", my_pca.nb_components)\n",
    "    print(\"eigen_values:\", my_pca.eigen_values)\n",
    "    print(\"eigen_vectors:\", my_pca.eigen_vectors)  \n",
    "        \n",
    "    # Calculate PCA using homebrew code, nb_components=1\n",
    "    my_pca.nb_components=1\n",
    "    my_pca.fit(data)\n",
    "    print()\n",
    "    print(\"pca homebrew nb_components=\", my_pca.nb_components)\n",
    "    print(\"eigen_values:\", my_pca.eigen_values)\n",
    "    print(\"eigen_vectors:\", my_pca.eigen_vectors)\n",
    "    \n",
    "    # Calculate transformation using homebrew code, nb_coomponent=2\n",
    "    my_pca.nb_components=2\n",
    "    my_pca.transform(data)\n",
    "    print()\n",
    "    print(\"Transform using homebrew code, nb_components=\", my_pca.nb_components)\n",
    "    print(\"Transform:\", my_pca.projection)\n",
    "    \n",
    "    # Calculate transformation using homebrew code, nb_coomponent=1\n",
    "    my_pca.nb_components=1\n",
    "    #my_pca.transform(data)\n",
    "    #print()\n",
    "    #print(\"Transform using homebrew code, nb_components=\", my_pca.nb_components)\n",
    "    #print(\"Transform:\", my_pca.projection)\n",
    "    \n",
    "\n",
    "data = build_dataset()    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between Scikit and homebrew PCA\n",
    "## Scikit\n",
    "\n",
    "  * There are 2 eigen values: **580** and **0.45**. \n",
    "  * Because the 2nd eigen value is low we can deduct that the second eigen vector will not carry significant information and can be ignored.\n",
    "  * Looking at the values of the eigen vectors we can clearly see that they are **orthogonal**\n",
    "  * The first eigen vector is **[-0.24191617 -0.97029715]**\n",
    "\n",
    "```python\n",
    "scikit.pca with nb_components=2\n",
    "eigen_values: [5.80787811e+02 4.56934586e-01]\n",
    "eigen_vectors: [[-0.24191617 -0.97029715]\n",
    " [-0.97029715  0.24191617]]\n",
    "```\n",
    "## Homebrew implementation\n",
    "  * There are 2 eigen values: **580** and **0.45**. \n",
    "  * Because the 2nd eigen value is low we can deduct that the second eigen vector will not carry significant information and can be ignored.\n",
    "  * Looking at the values of the eigen vectors we can clearly see that they are **orthogonal**\n",
    "  * The first eigen vector is **[ 0.24191617 -0.97029715]**\n",
    "  \n",
    "```python\n",
    "pca homebrew nb_components= 2\n",
    "eigen_values: [5.80787811e+02 4.56934586e-01]\n",
    "eigen_vectors: [[ 0.24191617 -0.97029715]\n",
    " [-0.97029715 -0.24191617]]\n",
    "```\n",
    "`I note sign discrepencies between the eigen vectors returned by Scikit and the Homebrew implementation. The eigen basis is therefore different. I am looking for an explanation.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PCA using scikit, nb_components=2\n",
    "pca = scikit_pca(data, 2)\n",
    "print()\n",
    "print(\"scikit.pca with nb_components=2\")\n",
    "print(\"eigen_values:\", pca.explained_variance_)\n",
    "print(\"eigen_vectors:\", pca.components_)\n",
    "\n",
    "# Calculate PCA using scikit, nb_components=1\n",
    "pca = scikit_pca(data, 1)\n",
    "print()\n",
    "print(\"scikit.pca with nb_components=1\")\n",
    "print(\"eigen_values:\", pca.explained_variance_)\n",
    "print(\"eigen_vectors:\", pca.components_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison between nb_component=1 and nb_component=2\n",
    "\n",
    "Since the value of the second eigen vector low, the second eigen vector can be ignored and thus the resulting eigen space can be simplified to **one dimension**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
