{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student Name: Cormac Lavery\n",
    "\n",
    "Student ID: 16139658"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'as' keyword allows you to invoke functionality from the module using an alias for the module name. For example: np.mean() instead of numpy.mean()\n",
    "- The from keyword allows you to only import the functionality of interest, for example above we import only the PCA class from the sklearn.decomposition module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import eig\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per E-tivity instructions: Use of the matrix class is discouraged, but to allow us to simplify the code slightly, we will use it this week. Its first use will be to store the data that you will perform the PCA transform on. Note that you will likely obtain a higher score if your final version does not use the matrix class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 739,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a_x = 0.05\n",
    "a_y= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data =  np.array([[n*(1+a_x*(rand.random()-0.5)),4*n+ a_y*(rand.random()-0.5)] for n in range(20)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy shape property is very useful to get an insight in the dimensions of your data, for example to check whether the features (in this case 2) or the samples (in this case 20) are in the rows or the columns. The notation used here (with columns containing the features and rows containing separate examples) is the standard for Scikitlearn and many other machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPCA:\n",
    "\n",
    "    def __init__(self, n_components = 2):\n",
    "        self.n_components = n_components\n",
    "\n",
    "\n",
    "    def fit(self, matrix):\n",
    "        # subtract the mean of each column from the column\n",
    "        self.mean = mean_data = np.mean(data, axis=0)\n",
    "        centered_data = data - self.mean\n",
    "        #calculate the covariance of the data with mean subtracted\n",
    "        cov_data = np.cov(centered_data,rowvar=False)\n",
    "        values, vectors = eig(cov_data)        \n",
    "        #(square each value so that magnitude and not sign is taken into account when ordering)\n",
    "        sorted_eigen_values_indexes = np.square(values).argsort()[::-1]\n",
    "        sorted_eigen_values = values[sorted_eigen_values_indexes]\n",
    "        sorted_eigen_vectors = vectors[sorted_eigen_values_indexes]\n",
    "        self.eigen_values = sorted_eigen_values[:self.n_components]\n",
    "        self.eigen_vectors = sorted_eigen_vectors.T[:self.n_components,:]\n",
    "        \n",
    "    def transform(self, matrix):\n",
    "        matrix = matrix - self.mean\n",
    "        return np.dot(matrix, self.eigen_vectors.T)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "my pca eigen vectors: \n[[ 0.24156234 -0.9703853 ]\n [-0.9703853  -0.24156234]]\nscikit pca eigen vectors: \n[[ 0.24156234  0.9703853 ]\n [ 0.9703853  -0.24156234]]\n\n\nmy pca eigen values: \n[6.06795704e+02 4.84722202e-01]\nscikit pca eigen values: \n[6.06795704e+02 4.84722202e-01]\n\nmy pca transform: \n[[ 34.12767595  18.34561095]\n [ 31.68313504  16.69547127]\n [ 27.93864757  14.72416534]\n [ 24.74268068  12.89146403]\n [ 19.36357237  10.5694729 ]\n [ 14.64882208   8.42053905]\n [ 15.69723632   7.45055837]\n [  7.35483321   4.40133328]\n [  2.24826967   2.13172905]\n [  4.54198792   1.63582239]\n [  2.17679722   0.13841228]\n [ -8.10724234  -3.53799763]\n [-12.12760786  -5.5020691 ]\n [-11.17554292  -6.48086173]\n [-18.30244096  -8.87338791]\n [-22.4359812  -10.97483379]\n [-22.41481374 -12.62980011]\n [-21.37095641 -13.10466828]\n [-30.55308368 -16.73056457]\n [-38.03598893 -19.5703958 ]]\nscikit pca transform: \n[[-38.74555072  -0.2049534 ]\n [-35.81268562   0.1065646 ]\n [-31.58101563   0.09233006]\n [-27.8988315    0.21282254]\n [-22.05890144  -0.25799162]\n [-16.88692789  -0.57020407]\n [-17.3582437    0.7780898 ]\n [ -8.55990966  -0.43960531]\n [ -2.98527698  -0.82891892]\n [ -4.77881794   0.68444742]\n [ -1.98764473   0.89826084]\n [  8.81976256  -0.67571725]\n [ 13.29172269  -0.82567831]\n [ 12.90964295   0.48522892]\n [ 20.32645544  -0.74267567]\n [ 24.96278574  -0.82435281]\n [ 25.71996512   0.64739478]\n [ 25.02055719   1.55622175]\n [ 34.83096894   0.45422054]\n [ 42.77194517  -0.54548389]]\n\ndifference between eigen values: \n[ 1.13686838e-13 -1.52655666e-14]\ndifference between eigen vectors: \n[[-2.77555756e-17  1.94077060e+00]\n [ 1.94077060e+00  2.77555756e-17]]\ndifference between transforms: \n[[-72.87322667 -18.55056435]\n [-67.49582066 -16.58890667]\n [-59.51966321 -14.63183528]\n [-52.64151218 -12.67864149]\n [-41.4224738  -10.82746452]\n [-31.53574997  -8.99074312]\n [-33.05548003  -6.67246858]\n [-15.91474286  -4.84093859]\n [ -5.23354665  -2.96064797]\n [ -9.32080586  -0.95137497]\n [ -4.16444194   0.75984855]\n [ 16.9270049    2.86228038]\n [ 25.41933055   4.67639079]\n [ 24.08518587   6.96609065]\n [ 38.6288964    8.13071224]\n [ 47.39876694  10.15048099]\n [ 48.13477886  13.27719489]\n [ 46.3915136   14.66089002]\n [ 65.38405262  17.18478511]\n [ 80.8079341   19.02491191]]\n"
     ]
    }
   ],
   "source": [
    "scikit_pca = PCA(n_components=2)\n",
    "scikit_pca.fit(data)\n",
    "scikit_transform = scikit_pca.transform(data)\n",
    "scikit_pca_eigen_vectors = scikit_pca.components_\n",
    "scikit_pca_eigen_values = scikit_pca.explained_variance_\n",
    "\n",
    "\n",
    "my_pca = MyPCA(n_components=2)\n",
    "my_pca.fit(data)\n",
    "my_pca_transform = my_pca.transform(data)\n",
    "my_pca_eigen_vectors = my_pca.eigen_vectors\n",
    "my_pca_eigen_values = my_pca.eigen_values\n",
    "\n",
    "print(\"my pca eigen vectors: \\n{}\".format(my_pca_eigen_vectors))\n",
    "print(\"scikit pca eigen vectors: \\n{}\".format(scikit_pca_eigen_vectors))\n",
    "print()\n",
    "print()\n",
    "print(\"my pca eigen values: \\n{}\".format(my_pca_eigen_values))\n",
    "print(\"scikit pca eigen values: \\n{}\".format(scikit_pca_eigen_values))\n",
    "print()\n",
    "print(\"my pca transform: \\n{}\".format(my_pca_transform))\n",
    "print(\"scikit pca transform: \\n{}\".format(scikit_transform))\n",
    "print()\n",
    "print(\"difference between eigen values: \\n{}\".format(scikit_pca_eigen_values - my_pca_eigen_values))\n",
    "print(\"difference between eigen vectors: \\n{}\".format(scikit_pca_eigen_vectors - my_pca_eigen_vectors))\n",
    "print(\"difference between transforms: \\n{}\".format(scikit_transform - my_pca_transform))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My eigen values match however I note that the eigen vectors do not match for my PCA class and the scikit implementation. My transform also does not match the scikit PCA transform.\n",
    "\n",
    "The magnitude match but the signs do not. I found the following stack overflow on someone else who had the same issue.\n",
    "https://stackoverflow.com/questions/44765682/in-sklearn-decomposition-pca-why-are-components-negative\n",
    "\n",
    "The answer seems to be that although the sign is different it is not the signs that we are interested in but the plance that the components lie on. In the following chart I will show that the resulting components are either in the same of directly opposite directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 745,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "V = scikit_pca_eigen_vectors\n",
    "W = my_pca_eigen_vectors\n",
    "origin = [0], [0] # origin point\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.quiver(*origin, W, V, color=['r','b','g'], scale=3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "In the following script I show that my transform function is calculating the values correctly by manually changing the eigen vectors in my PCA to the ones caclulated by the scikit PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scikit pca transform: \n[[-38.74555072  -0.2049534 ]\n [-35.81268562   0.1065646 ]\n [-31.58101563   0.09233006]\n [-27.8988315    0.21282254]\n [-22.05890144  -0.25799162]\n [-16.88692789  -0.57020407]\n [-17.3582437    0.7780898 ]\n [ -8.55990966  -0.43960531]\n [ -2.98527698  -0.82891892]\n [ -4.77881794   0.68444742]\n [ -1.98764473   0.89826084]\n [  8.81976256  -0.67571725]\n [ 13.29172269  -0.82567831]\n [ 12.90964295   0.48522892]\n [ 20.32645544  -0.74267567]\n [ 24.96278574  -0.82435281]\n [ 25.71996512   0.64739478]\n [ 25.02055719   1.55622175]\n [ 34.83096894   0.45422054]\n [ 42.77194517  -0.54548389]]\n\nmy pca transform with scikit eigen vectors: \n[[-38.74555072  -0.2049534 ]\n [-35.81268562   0.1065646 ]\n [-31.58101563   0.09233006]\n [-27.8988315    0.21282254]\n [-22.05890144  -0.25799162]\n [-16.88692789  -0.57020407]\n [-17.3582437    0.7780898 ]\n [ -8.55990966  -0.43960531]\n [ -2.98527698  -0.82891892]\n [ -4.77881794   0.68444742]\n [ -1.98764473   0.89826084]\n [  8.81976256  -0.67571725]\n [ 13.29172269  -0.82567831]\n [ 12.90964295   0.48522892]\n [ 20.32645544  -0.74267567]\n [ 24.96278574  -0.82435281]\n [ 25.71996512   0.64739478]\n [ 25.02055719   1.55622175]\n [ 34.83096894   0.45422054]\n [ 42.77194517  -0.54548389]]\n\nnew difference between transforms: \n[[0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]\n [0. 0.]]\n\n"
     ]
    }
   ],
   "source": [
    "my_pca.eigen_vectors = scikit_pca_eigen_vectors\n",
    "test_transform = my_pca.transform(data)\n",
    "print(\"scikit pca transform: \\n{}\\n\".format(scikit_transform))\n",
    "print(\"my pca transform with scikit eigen vectors: \\n{}\\n\".format(test_transform))\n",
    "print(\"new difference between transforms: \\n{}\\n\".format(scikit_transform - test_transform))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare scikit PCA with n_components:1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_components: 1\neigen vectors: \n[[0.24156234 0.9703853 ]]\neigen values: \n[606.79570422]\ntransform: \n[[-38.74555072]\n [-35.81268562]\n [-31.58101563]\n [-27.8988315 ]\n [-22.05890144]\n [-16.88692789]\n [-17.3582437 ]\n [ -8.55990966]\n [ -2.98527698]\n [ -4.77881794]\n [ -1.98764473]\n [  8.81976256]\n [ 13.29172269]\n [ 12.90964295]\n [ 20.32645544]\n [ 24.96278574]\n [ 25.71996512]\n [ 25.02055719]\n [ 34.83096894]\n [ 42.77194517]]\n\nn_components: 2\neigen vectors: \n[[ 0.24156234  0.9703853 ]\n [ 0.9703853  -0.24156234]]\neigen values: \n[6.06795704e+02 4.84722202e-01]\ntransform: \n[[-38.74555072  -0.2049534 ]\n [-35.81268562   0.1065646 ]\n [-31.58101563   0.09233006]\n [-27.8988315    0.21282254]\n [-22.05890144  -0.25799162]\n [-16.88692789  -0.57020407]\n [-17.3582437    0.7780898 ]\n [ -8.55990966  -0.43960531]\n [ -2.98527698  -0.82891892]\n [ -4.77881794   0.68444742]\n [ -1.98764473   0.89826084]\n [  8.81976256  -0.67571725]\n [ 13.29172269  -0.82567831]\n [ 12.90964295   0.48522892]\n [ 20.32645544  -0.74267567]\n [ 24.96278574  -0.82435281]\n [ 25.71996512   0.64739478]\n [ 25.02055719   1.55622175]\n [ 34.83096894   0.45422054]\n [ 42.77194517  -0.54548389]]\n\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in [1,2]:\n",
    "    n_pca = PCA(n_components=i)\n",
    "    n_pca.fit(data)\n",
    "    n_transform = n_pca.transform(data)\n",
    "    my_pca_eigen_vectors = n_pca.components_\n",
    "    my_pca_eigen_values = n_pca.explained_variance_\n",
    "    print(\"n_components: {}\".format(i))\n",
    "    print(\"eigen vectors: \\n{}\".format(my_pca_eigen_vectors))\n",
    "    print(\"eigen values: \\n{}\".format(my_pca_eigen_values))\n",
    "    print(\"transform: \\n{}\".format(n_transform))\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences noted:\n",
    "1. the eigen values are different by many orders of magnitude\n",
    "2. the eigen vectors are equal for each is equal to the first n rows of the n(max) eigen vectors\n",
    "3. the transforms are equal to the first n columns of the n(max) transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
