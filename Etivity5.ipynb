{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etivity 5- PCA\n",
    "\n",
    "#### Student Name:   Mark Murnane\n",
    "\n",
    "#### Student ID:     18195326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'as' keyword allows you to invoke functionality from the module using an alias for the module name. For example: np.mean() instead of numpy.mean()\n",
    "- The from keyword allows you to only import the functionality of interest, for example above we import only the PCA class from the sklearn.decomposition module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import eig\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per E-tivity instructions: Use of the matrix class is discouraged, but to allow us to simplify the code slightly, we will use it this week. Its first use will be to store the data that you will perform the PCA transform on. Note that you will likely obtain a higher score if your final version does not use the matrix class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_x = 0.05\n",
    "a_y= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        , -1.93097759],\n",
       "       [ 1.01682504,  1.48405774],\n",
       "       [ 1.95369055,  9.98747245],\n",
       "       [ 3.0360641 , 12.11450332],\n",
       "       [ 3.96978947, 19.84426276],\n",
       "       [ 5.05394185, 16.08259431],\n",
       "       [ 5.99920527, 23.42721451],\n",
       "       [ 6.95554962, 27.2713951 ],\n",
       "       [ 7.967567  , 36.58600484],\n",
       "       [ 8.99864427, 38.04473164],\n",
       "       [ 9.85257175, 42.71066421],\n",
       "       [11.12428555, 44.99105371],\n",
       "       [12.26634523, 52.18701364],\n",
       "       [12.83043713, 55.31699816],\n",
       "       [14.00188208, 59.18937489],\n",
       "       [14.898028  , 61.41449306],\n",
       "       [15.93583201, 67.41203463],\n",
       "       [17.19933308, 70.56456681],\n",
       "       [18.26996494, 74.4742251 ],\n",
       "       [19.29686516, 76.44163097]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  np.array([[n*(1+a_x*(rand.random()-0.5)),4*n+ a_y*(rand.random()-0.5)] for n in range(20)])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy shape property is very useful to get an insight in the dimensions of your data, for example to check whether the features (in this case 2) or the samples (in this case 20) are in the rows or the columns. The notation used here (with columns containing the features and rows containing separate examples) is the standard for Scikitlearn and many other machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit\n",
    "\n",
    "The `fit()` values from Scikitlearn are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikitlearn PCA Eigen vectors\n",
      "\n",
      "[[-0.23226835 -0.97265174]\n",
      " [ 0.97265174 -0.23226835]]\n",
      "\n",
      "Scikitlearn PCA Eigen values\n",
      "\n",
      "[6.55734567e+02 2.76169980e-01]\n",
      "\n",
      "Scikitlearn PCA Variance Ratio\n",
      "\n",
      "[9.99579016e-01 4.20983933e-04]\n",
      "\n",
      "Transform:\n",
      "\n",
      "[[38.33993019  0.38432191]\n",
      " [35.93008999  1.86508869]\n",
      " [33.5202498   3.34585547]]\n"
     ]
    }
   ],
   "source": [
    "#A = np.array([[1, 2], [3, 4], [5, 6]]) \n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "pca.fit(data)\n",
    "\n",
    "print(\"Scikitlearn PCA Eigen vectors\\n\")\n",
    "print(pca.components_)\n",
    "print(\"\\nScikitlearn PCA Eigen values\\n\")\n",
    "print(pca.explained_variance_)\n",
    "print(\"\\nScikitlearn PCA Variance Ratio\\n\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "print(\"\\nTransform:\\n\")\n",
    "print(pca.transform(A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Implementation\n",
    "\n",
    "I changed the definition of the data from an `np.matrix` to an `np.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eigenvalues of the data are [6.55734567e+02 2.76169980e-01]\n",
      "\n",
      "The Eigenvectors of the data are\n",
      "[[ 0.23226835 -0.97265174]\n",
      " [-0.97265174 -0.23226835]]\n",
      "\n",
      "The transform of the data is\n",
      "[[34.37680907 16.98036949]\n",
      " [32.8960423  14.5705293 ]\n",
      " [31.41527552 12.1606891 ]]\n"
     ]
    }
   ],
   "source": [
    "class myPCA(object):\n",
    "    def __init__(self, n_components):\n",
    "        # TODO: Set the number of components to a sensible default if none is used\n",
    "        self._num_components = n_components\n",
    "        \n",
    "    def fit (self, A):\n",
    "        \"\"\"Performs PCA algorithm to derive the mean, Eigenvalues and Eigenvectors of the array A.\n",
    "        \n",
    "        Args:\n",
    "            A (numpy.ndarray)    A 2D array where each column represents a dimension and the rows contain their observations.             \n",
    "        \"\"\"\n",
    "        \n",
    "        # Performs the PCA algorithm on the input array to \"train\" the model\n",
    "        # The mean, Eigenvalues and Eigenvectors represent the model and are stored for later use in transform\n",
    "        \n",
    "        # First of all, calculate the mean for each of the columns\n",
    "        self._mean = np.array([np.mean(A[:,column]) for column in range(A.shape[1])])\n",
    "        \n",
    "        # Then calculate the centred matrix, which deducts the mean from each value\n",
    "        centered = A - self._mean\n",
    "        \n",
    "        # Calculate the covariant matrix for the centered matrix.\n",
    "        covariant = np.cov(centered, rowvar=False)\n",
    "                \n",
    "        # Next, generate the Eigen values and Eigen vectors for the covariant matrix.\n",
    "        self.eigenvalues, eigenvectors = eig(covariant)\n",
    "        \n",
    "        # Sort the Eigen values and Eigen vectors descending\n",
    "        # First up get the sort order for the eigenvalues        \n",
    "        sort_order = np.argsort(self.eigenvalues)\n",
    "        \n",
    "        # Then sort the Eigen values and then sort the Eigen vectors based on how the Eigen values were sorted\n",
    "        self.eigenvalues.sort()\n",
    "        eigenvectors = eigenvectors[sort_order]\n",
    "        \n",
    "        # Then reverse both and they should be in descending order\n",
    "        self.eigenvalues = self.eigenvalues[::-1]\n",
    "        eigenvectors = eigenvectors[::-1]    \n",
    "        \n",
    "        \n",
    "        if (self._num_components < eigenvectors.shape[1]):\n",
    "            # Here we'd split the feature_matrix\n",
    "            self.feature_vector_matrix = eigenvectors[:,:self._num_components]\n",
    "        else:\n",
    "            self.feature_vector_matrix = eigenvectors\n",
    "        \n",
    "        \n",
    "    def transform(self, data):\n",
    "        \"\"\"Applies the transformation represented by this PCA model to the input data set.\n",
    "        \n",
    "        Args:\n",
    "            data (numpy.ndarray)   Input data set where each column represents a dimension and the rows contain their observations.\n",
    "                                   The shape of the data set should match that used for the PCA.fit() method.\n",
    "                                   \n",
    "        Raises:\n",
    "            TODO          Error when the model hasn't been trained.\n",
    "            TODO          Error when the data set is a different dimension to the trained model\n",
    "        \"\"\"\n",
    "\n",
    "        # The transform centres the input data set, and then apples the Eigen vectors from this model \n",
    "        # (reduced to the number of components) to the input data\n",
    "        \n",
    "        data_centered = data - self._mean\n",
    "              \n",
    "        return (self.feature_vector_matrix.T @ (data_centered.T)).T\n",
    "        \n",
    "        \n",
    "       \n",
    "myP = myPCA(2)\n",
    "myP.fit(data)\n",
    "print(f\"The Eigenvalues of the data are {myP.eigenvalues}\\n\")\n",
    "print(f\"The Eigenvectors of the data are\\n{myP.feature_vector_matrix}\")\n",
    "print()\n",
    "print(f\"The transform of the data is\\n{myP.transform(A)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above `fit` method it was necessary to override the default behaviour of NumPy's `cov()` function.  It assumes that each row in the data is a variable, with the column values of that row the data set for that variable.  Our data set is organised with each column representing a variable, and the rows containg the data.  One option was to _transpose_ the centered matrix; the other was to tell `np.cov()` to use columns as data sets.\n",
    "\n",
    "#### Output comparison\n",
    "\n",
    "The Eigen vectors produced by my calculation have components with the same magnitude as those produced by Scikitlean, but not the same sign or position.  Initially, I wasn't sorting the Eigenvalues and Eigenvectors, but I know do this.  From the [blog](https://machinelearningmastery.com/calculate-principal-component-analysis-scratch-python/) linked by Pep:\n",
    "\n",
    "\"The eigenvectors can be sorted by the eigenvalues in descending order to provide a ranking of the components or axes of the new subspace for A.\"\n",
    "\n",
    "But The Scikitlean PCA algorithm is changing the signs of the vectors, so need to understand this more.  My transform produces similar ratios, but different numbers for the second dimension of the data set.  Simpler training sets such as the array `A` produce very similar results, so it may be an issue of scaling.\n",
    "\n",
    "TODO: Follow up on scaling, which is mentioned by many online resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikitlearn PCA n_components differences\n",
    "\n",
    "The following code shows output from Scitkitlearn PCA with n_components=1 vs. the output earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.70710678 0.70710678]]\n",
      "[8.]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=1)\n",
    "pca.fit(A)\n",
    "print(pca.components_)\n",
    "print(pca.explained_variance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The components value demonstrates that Scikitlearn can be instructed to deal only with a subset of the dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
