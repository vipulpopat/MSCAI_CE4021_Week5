{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Etivity 5- PCA\n",
    "\n",
    "#### Student Name:   Mark Murnane\n",
    "\n",
    "#### Student ID:     18195326"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The 'as' keyword allows you to invoke functionality from the module using an alias for the module name. For example: np.mean() instead of numpy.mean()\n",
    "- The from keyword allows you to only import the functionality of interest, for example above we import only the PCA class from the sklearn.decomposition module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import eig\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As per E-tivity instructions: Use of the matrix class is discouraged, but to allow us to simplify the code slightly, we will use it this week. Its first use will be to store the data that you will perform the PCA transform on. Note that you will likely obtain a higher score if your final version does not use the matrix class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_x = 0.05\n",
    "a_y= 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  3.02643882],\n",
       "       [ 1.00302468,  3.77581571],\n",
       "       [ 2.01834168,  4.77098768],\n",
       "       [ 2.98684566, 14.1154116 ],\n",
       "       [ 3.96436336, 15.80340231],\n",
       "       [ 5.0356314 , 15.24896614],\n",
       "       [ 6.04005009, 26.80550406],\n",
       "       [ 6.94104483, 23.74771991],\n",
       "       [ 7.92010654, 35.58240131],\n",
       "       [ 9.2201525 , 33.76838478],\n",
       "       [10.2426964 , 37.63014143],\n",
       "       [10.79983959, 45.95119884],\n",
       "       [11.71261515, 48.51996017],\n",
       "       [13.25754503, 51.16668769],\n",
       "       [13.79980117, 51.105388  ],\n",
       "       [15.14412871, 63.66125497],\n",
       "       [16.1666178 , 59.24647693],\n",
       "       [16.89223507, 67.10744822],\n",
       "       [17.80992819, 67.48190716],\n",
       "       [18.81448752, 74.333798  ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data =  np.array([[n*(1+a_x*(rand.random()-0.5)),4*n+ a_y*(rand.random()-0.5)] for n in range(20)])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy shape property is very useful to get an insight in the dimensions of your data, for example to check whether the features (in this case 2) or the samples (in this case 20) are in the rows or the columns. The notation used here (with columns containing the features and rows containing separate examples) is the standard for Scikitlearn and many other machine learning algorithms.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit\n",
    "\n",
    "The `fit()` values from Scikitlearn are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24596569  0.96927853]\n",
      " [-0.96927853  0.24596569]]\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(data)\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My Implementation\n",
    "\n",
    "I changed the definition of the data from an `np.matrix` to an `np.array`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Eigen values of the data are [5.48592104e-01 5.64794103e+02]\n",
      "The Eigen vectors of the data are\n",
      "[[-0.96927853 -0.24596569]\n",
      " [ 0.24596569 -0.96927853]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "class myPCA(object):\n",
    "    def __init__(self, n_components):\n",
    "        self.num_components = n_components\n",
    "        \n",
    "    def fit (self, A):\n",
    "        # Here we'll calculate the Eigen vectors and Eigen values\n",
    "        \n",
    "        # First of all, calculate the mean for each of the columns\n",
    "        self.mean = np.array([np.mean(A[:,column]) for column in range(A.shape[1])])\n",
    "        \n",
    "        # Then calculate the centred matrix, which deducts the mean from each value\n",
    "        self.centered = A - self.mean\n",
    "        \n",
    "        # Calculate the covariant matrix for the centered matrix.\n",
    "        self.covariant = np.cov(self.centered, rowvar=False)\n",
    "                \n",
    "        # Next, generate the Eigen values and Eigen vectors for the covariant matrix.\n",
    "        self.e_values, self.e_vectors = eig(self.covariant)\n",
    "        \n",
    "    def transform(self):\n",
    "        pass\n",
    "        \n",
    "myP = myPCA(2)\n",
    "myP.fit(data)\n",
    "print(f\"The Eigen values of the data are {myP.e_values}\")\n",
    "print(f\"The Eigen vectors of the data are\\n{myP.e_vectors}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above `fit` method it was necessary to override the default behaviour of NumPy's `cov()` function.  It assumes that each row in the data is a variable, with the column values of that row the data set for that variable.  Our data set is organised with each column representing a variable, and the rows containg the data.  One option was to _transpose_ the centered matrix; the other was to tell `np.cov()` to use columns as data sets.\n",
    "\n",
    "#### Output comparison\n",
    "\n",
    "The Eigen vectors produced by my calculation have components with the same magnitude as those produced by Scikitlean, but not the same sign or position.  Needs further investigation to understand."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
